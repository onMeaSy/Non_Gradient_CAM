{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb48ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: cats-image/image\n",
      "Found cached dataset cats-image (C:/Users/sukan/.cache/huggingface/datasets/huggingface___cats-image/image/1.9.0/68fbc793fb10cd165e490867f5d61fa366086ea40c73e549a020103dcb4f597e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc168eda6bbb4e7a97a3966d0474a80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from typing import List, Callable, Optional\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "img_tensor = transforms.ToTensor()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cd4136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58103b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "print(type(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1ead03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    517\u001b[0m     )\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f3ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import torch\n",
    "import ttach as tta\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageTk, Image\n",
    "from typing import Callable, List, Tuple\n",
    "import matplotlib\n",
    "from torchvision import models\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import transforms\n",
    "from typing import List, Callable, Optional\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3183714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileViTForImageClassification\n",
    "model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\")\n",
    "target_layer = model.mobilevit.encoder.layer[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553b4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8797a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9732a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileViTForImageClassification(\n",
      "  (mobilevit): MobileViTModel(\n",
      "    (conv_stem): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (encoder): MobileViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): MobileViTMobileNetLayer(\n",
      "          (layer): ModuleList(\n",
      "            (0): MobileViTInvertedResidual(\n",
      "              (expand_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (conv_3x3): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (reduce_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): MobileViTMobileNetLayer(\n",
      "          (layer): ModuleList(\n",
      "            (0): MobileViTInvertedResidual(\n",
      "              (expand_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (conv_3x3): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (reduce_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): MobileViTInvertedResidual(\n",
      "              (expand_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (conv_3x3): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (reduce_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (2): MobileViTInvertedResidual(\n",
      "              (expand_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (conv_3x3): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (activation): SiLUActivation()\n",
      "              )\n",
      "              (reduce_1x1): MobileViTConvLayer(\n",
      "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): MobileViTLayer(\n",
      "          (downsampling_layer): MobileViTInvertedResidual(\n",
      "            (expand_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (conv_3x3): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (reduce_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_kxk): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (conv_1x1): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(96, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (transformer): MobileViTTransformer(\n",
      "            (layer): ModuleList(\n",
      "              (0): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (key): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (value): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=144, out_features=288, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=288, out_features=144, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (1): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (key): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (value): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=144, out_features=288, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=288, out_features=144, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layernorm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_projection): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(144, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (fusion): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "        )\n",
      "        (3): MobileViTLayer(\n",
      "          (downsampling_layer): MobileViTInvertedResidual(\n",
      "            (expand_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (conv_3x3): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (reduce_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_kxk): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (conv_1x1): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (transformer): MobileViTTransformer(\n",
      "            (layer): ModuleList(\n",
      "              (0): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (1): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (2): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (3): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layernorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_projection): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (fusion): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "        )\n",
      "        (4): MobileViTLayer(\n",
      "          (downsampling_layer): MobileViTInvertedResidual(\n",
      "            (expand_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (conv_3x3): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activation): SiLUActivation()\n",
      "            )\n",
      "            (reduce_1x1): MobileViTConvLayer(\n",
      "              (convolution): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (conv_kxk): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (conv_1x1): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(160, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (transformer): MobileViTTransformer(\n",
      "            (layer): ModuleList(\n",
      "              (0): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (1): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (2): MobileViTTransformerLayer(\n",
      "                (attention): MobileViTAttention(\n",
      "                  (attention): MobileViTSelfAttention(\n",
      "                    (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (output): MobileViTSelfOutput(\n",
      "                    (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): MobileViTIntermediate(\n",
      "                  (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "                  (intermediate_act_fn): SiLUActivation()\n",
      "                )\n",
      "                (output): MobileViTOutput(\n",
      "                  (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "                (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layernorm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv_projection): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "          (fusion): MobileViTConvLayer(\n",
      "            (convolution): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activation): SiLUActivation()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1_exp): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=True)\n",
      "  (classifier): Linear(in_features=640, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54d4f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): MobileViTMobileNetLayer(\n",
      "    (layer): ModuleList(\n",
      "      (0): MobileViTInvertedResidual(\n",
      "        (expand_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (conv_3x3): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (reduce_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): MobileViTMobileNetLayer(\n",
      "    (layer): ModuleList(\n",
      "      (0): MobileViTInvertedResidual(\n",
      "        (expand_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (conv_3x3): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "          (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (reduce_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): MobileViTInvertedResidual(\n",
      "        (expand_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (conv_3x3): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (reduce_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): MobileViTInvertedResidual(\n",
      "        (expand_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (conv_3x3): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): SiLUActivation()\n",
      "        )\n",
      "        (reduce_1x1): MobileViTConvLayer(\n",
      "          (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): MobileViTLayer(\n",
      "    (downsampling_layer): MobileViTInvertedResidual(\n",
      "      (expand_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (conv_3x3): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (reduce_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_kxk): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (conv_1x1): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(96, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (transformer): MobileViTTransformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (key): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (value): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=144, out_features=288, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=288, out_features=144, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (key): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (value): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=144, out_features=288, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=288, out_features=144, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "    (conv_projection): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(144, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (fusion): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "  )\n",
      "  (3): MobileViTLayer(\n",
      "    (downsampling_layer): MobileViTInvertedResidual(\n",
      "      (expand_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (conv_3x3): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (reduce_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_kxk): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (conv_1x1): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (transformer): MobileViTTransformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=192, out_features=384, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=384, out_features=192, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (conv_projection): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (fusion): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "  )\n",
      "  (4): MobileViTLayer(\n",
      "    (downsampling_layer): MobileViTInvertedResidual(\n",
      "      (expand_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (conv_3x3): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "        (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): SiLUActivation()\n",
      "      )\n",
      "      (reduce_1x1): MobileViTConvLayer(\n",
      "        (convolution): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_kxk): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (conv_1x1): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(160, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (transformer): MobileViTTransformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): MobileViTTransformerLayer(\n",
      "          (attention): MobileViTAttention(\n",
      "            (attention): MobileViTSelfAttention(\n",
      "              (query): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (key): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (value): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): MobileViTSelfOutput(\n",
      "              (dense): Linear(in_features=240, out_features=240, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): MobileViTIntermediate(\n",
      "            (dense): Linear(in_features=240, out_features=480, bias=True)\n",
      "            (intermediate_act_fn): SiLUActivation()\n",
      "          )\n",
      "          (output): MobileViTOutput(\n",
      "            (dense): Linear(in_features=480, out_features=240, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "    (conv_projection): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "    (fusion): MobileViTConvLayer(\n",
      "      (convolution): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): SiLUActivation()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.mobilevit.encoder.layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7855d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
